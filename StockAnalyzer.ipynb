{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31fcc842-2cc7-4a9d-bf94-65863fb4b2e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.optimize import minimize\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b541261e-7206-478c-8914-fffe80772b90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StockAnalyzer:\n",
    "    def __init__(self, filepath):\n",
    "        self.df = pd.read_csv(filepath)\n",
    "        self.dfx = None\n",
    "        self.dfy = None\n",
    "        self.best_model = None  # Store best regression model\n",
    "        self.best_features = None\n",
    "        self.best_score = None\n",
    "        \n",
    "    def CleanData(self, drop_column_threshold = 0.1):\n",
    "        #define filepath\n",
    "        df = self.df.copy()\n",
    "        \n",
    "        # Remove commas and convert to float\n",
    "        df = df.replace(',', '', regex=True)  # Remove thousand separators\n",
    "        df = df.apply(pd.to_numeric, errors='coerce')  # Convert everything to float\n",
    "\n",
    "        #remove columns with excess missing inputs\n",
    "        #max_na based on threshold\n",
    "        max_na = len(df) * drop_column_threshold\n",
    "        \n",
    "        #Count na in column\n",
    "        column_nan_count = df.isnull().sum()\n",
    "        \n",
    "        #drop columns with na count > max_na\n",
    "        df = df.drop(columns=column_nan_count[column_nan_count > max_na].index)\n",
    "        \n",
    "        #drop rows with na \n",
    "        df = df.dropna()\n",
    "        \n",
    "        if df.empty:\n",
    "            print(\"Warning: DataFrame is empty after cleaning!\")\n",
    "            self.dfx, self.dfy = None, None\n",
    "            return None, None\n",
    "        \n",
    "        #define variable columns\n",
    "        self.dfx = df.drop(columns=df.columns[0])\n",
    "        self.dfy = df.iloc[: , 0]\n",
    "        \n",
    "        return self.dfx, self.dfy  \n",
    "            \n",
    "    def classify_features(self):\n",
    "        \"\"\"Classify features into risk, profitability, growth, and other categories based on keywords.\"\"\"\n",
    "        if self.dfx is None:\n",
    "            raise ValueError(\"Data has not been cleaned. Run CleanData() first.\")\n",
    "\n",
    "        # Define keywords for each category\n",
    "        risk_keywords = ['risk', 'debt', 'beta', 'volatility', 'leverage']\n",
    "        profitability_keywords = ['profit', 'margin', 'nim', 'income', 'earnings', 'eps', 'roe', 'roa']\n",
    "        growth_keywords = ['growth', 'change', 'increase', '%', 'yoy', 'chg']\n",
    "\n",
    "        # Initialize category dictionaries\n",
    "        self.feature_categories = {\n",
    "            'risk': [],\n",
    "            'profitability': [],\n",
    "            'growth': [],\n",
    "            'other': []\n",
    "        }\n",
    "\n",
    "        # Classify each feature\n",
    "        for column in self.dfx.columns:\n",
    "            col_lower = column.lower()\n",
    "\n",
    "            # Check each category\n",
    "            if any(keyword in col_lower for keyword in risk_keywords):\n",
    "                self.feature_categories['risk'].append(column)\n",
    "            elif any(keyword in col_lower for keyword in profitability_keywords):\n",
    "                self.feature_categories['profitability'].append(column)\n",
    "            elif any(keyword in col_lower for keyword in growth_keywords):\n",
    "                self.feature_categories['growth'].append(column)\n",
    "            else:\n",
    "                self.feature_categories['other'].append(column)\n",
    "\n",
    "        # Print classification results\n",
    "        print(\"\\nFeature Classification:\")\n",
    "        for category, features in self.feature_categories.items():\n",
    "            print(f\"\\n{category.capitalize()} features:\")\n",
    "            print(features if features else \"None found\")\n",
    "            \n",
    "    def validate_feature_combination(self, features):\n",
    "        \"\"\"Check if feature combination includes at least one from each required category.\"\"\"\n",
    "        if self.feature_categories is None:\n",
    "            raise ValueError(\"Features have not been classified. Run classify_features() first.\")\n",
    "            \n",
    "        has_risk = any(feature in self.feature_categories['risk'] for feature in features)\n",
    "        has_profitability = any(feature in self.feature_categories['profitability'] for feature in features)\n",
    "        has_growth = any(feature in self.feature_categories['growth'] for feature in features)\n",
    "        \n",
    "        return has_risk and has_profitability and has_growth\n",
    "    \n",
    "    def remove_multicollinear_features(self, threshold=5.0):\n",
    "        X = sm.add_constant(self.dfx)  # Add intercept\n",
    "        dropped_features = []\n",
    "        \n",
    "        #vif framework to remove weak collinear varaibles\n",
    "        while True:\n",
    "            vif_data = pd.DataFrame()\n",
    "            vif_data[\"Feature\"] = X.columns\n",
    "            vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "            # Drop feature with highest VIF (if above threshold)\n",
    "            high_vif = vif_data[vif_data[\"VIF\"] > threshold]\n",
    "            if high_vif.empty:\n",
    "                break  # Stop if no high-VIF features remain\n",
    "\n",
    "            feature_to_drop = high_vif.sort_values(\"VIF\", ascending=False).iloc[0][\"Feature\"]\n",
    "            if feature_to_drop == \"const\":\n",
    "                break  # Never drop intercept\n",
    "\n",
    "            X = X.drop(columns=[feature_to_drop])\n",
    "            dropped_features.append(feature_to_drop)\n",
    "\n",
    "        print(f\"Removed multicollinear features: {dropped_features}\")\n",
    "        self.dfx = X.drop(columns=\"const\", errors=\"ignore\")  # Update cleaned X\n",
    "    \n",
    "    def find_best_model(self, criterion='adj_r2', p_value=0.10):\n",
    "        if self.dfx is None or self.dfy is None:\n",
    "            raise ValueError(\"Data has not been cleaned. Run CleanData() first.\")\n",
    "        if self.feature_categories is None:\n",
    "            raise ValueError(\"Features have not been classified. Run classify_features() first.\")\n",
    "\n",
    "        \n",
    "        X = sm.add_constant(self.dfx)  # Add intercept\n",
    "        feature_names = X.columns[1:]  # Exclude intercept in naming\n",
    "        best_model = None\n",
    "        best_features = None\n",
    "        \n",
    "        #ensures at least one model is selected \n",
    "        best_score = float('-inf') if criterion == 'adj_r2' else float('inf')\n",
    "\n",
    "        # Try all possible feature combinations\n",
    "        for r in range(3, len(feature_names) + 1):\n",
    "            for subset in itertools.combinations(feature_names, r):\n",
    "                # Skip combinations that don't meet category requirements\n",
    "                if not self.validate_feature_combination(subset):\n",
    "                    continue\n",
    "                X_subset = X[['const'] + list(subset)]\n",
    "\n",
    "                model = sm.OLS(self.dfy, X_subset.astype(float)).fit()\n",
    "                p_values = model.pvalues[1:]  # Exclude intercept p-value\n",
    "\n",
    "                # Check if all selected features meet the p-value criterion\n",
    "                if all(p_values < p_value):  \n",
    "                    score = (\n",
    "                        model.rsquared_adj if criterion == 'adj_r2' else\n",
    "                        model.aic if criterion == 'aic' else\n",
    "                        model.bic\n",
    "                    )\n",
    "\n",
    "                    # Update best model based on criterion\n",
    "                    if (criterion == 'adj_r2' and score > best_score) or \\\n",
    "                       (criterion in ['aic', 'bic'] and score < best_score):\n",
    "                        best_model = model\n",
    "                        best_features = subset\n",
    "                        best_score = score\n",
    "\n",
    "        # Store best model & features\n",
    "        self.best_model = best_model\n",
    "        self.best_features = best_features\n",
    "        self.best_score = best_score\n",
    "        \n",
    "        if best_model is None:\n",
    "            print(\"No valid model found meeting all criteria (p-value and category requirements)\")\n",
    "        else:\n",
    "            print(\"\\nBest Model Features by Category:\")\n",
    "            for category in ['risk', 'profitability', 'growth', 'other']:\n",
    "                category_features = [f for f in best_features if f in self.feature_categories[category]]\n",
    "                print(f\"\\n{category.capitalize()}:\")\n",
    "                print(category_features if category_features else \"None\")\n",
    "\n",
    "    def get_best_model_summary(self):\n",
    "        \"\"\"Returns the summary of the best regression model.\"\"\"\n",
    "        if self.best_model:\n",
    "            return self.best_model.summary()\n",
    "        else:\n",
    "            return \"No model found. Run find_best_model() first.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b901f9c-e0ac-480d-869b-86aa4bcf6800",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Classification:\n",
      "\n",
      "Risk features:\n",
      "['Beta 3yr', 'Beta 5yr']\n",
      "\n",
      "Profitability features:\n",
      "['FE Val Roe Mean FQ1 Roll', 'Net Income 1 Yr Growth']\n",
      "\n",
      "Growth features:\n",
      "['Net Inc Pct Chg Yr/Yr', 'FE Growth Net_Inc Mean FQ1 Roll Over -2AM', 'FE Growth Net_Inc Mean FQ1 Over -1AM', 'FE Growth Period-on-Period Net_Inc Mean  Roll', 'FE Growth Net_Inc Mean FQ1 Over 0CY']\n",
      "\n",
      "Other features:\n",
      "None found\n",
      "Removed multicollinear features: []\n",
      "\n",
      "Best Model Features by Category:\n",
      "\n",
      "Risk:\n",
      "['Beta 3yr', 'Beta 5yr']\n",
      "\n",
      "Profitability:\n",
      "['FE Val Roe Mean FQ1 Roll']\n",
      "\n",
      "Growth:\n",
      "['FE Growth Net_Inc Mean FQ1 Roll Over -2AM', 'FE Growth Net_Inc Mean FQ1 Over -1AM', 'FE Growth Net_Inc Mean FQ1 Over 0CY']\n",
      "\n",
      "Other:\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>Price / Book Value</td> <th>  R-squared:         </th> <td>   0.803</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                    <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.796</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>              <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   116.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Fri, 14 Feb 2025</td>  <th>  Prob (F-statistic):</th> <td>5.56e-58</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>12:51:39</td>      <th>  Log-Likelihood:    </th> <td> -427.08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>   179</td>       <th>  AIC:               </th> <td>   868.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>   172</td>       <th>  BIC:               </th> <td>   890.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>     6</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>       <td>nonrobust</td>     <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                      <td></td>                         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                                     <td>   -1.5875</td> <td>    0.703</td> <td>   -2.257</td> <td> 0.025</td> <td>   -2.976</td> <td>   -0.199</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FE Val Roe Mean FQ1 Roll</th>                  <td>    1.1325</td> <td>    0.044</td> <td>   25.598</td> <td> 0.000</td> <td>    1.045</td> <td>    1.220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Beta 3yr</th>                                  <td>    4.1676</td> <td>    1.011</td> <td>    4.123</td> <td> 0.000</td> <td>    2.173</td> <td>    6.163</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Beta 5yr</th>                                  <td>   -3.7333</td> <td>    1.065</td> <td>   -3.507</td> <td> 0.001</td> <td>   -5.835</td> <td>   -1.632</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FE Growth Net_Inc Mean FQ1 Roll Over -2AM</th> <td>   -0.0159</td> <td>    0.005</td> <td>   -3.111</td> <td> 0.002</td> <td>   -0.026</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FE Growth Net_Inc Mean FQ1 Over -1AM</th>      <td>    0.0521</td> <td>    0.028</td> <td>    1.889</td> <td> 0.061</td> <td>   -0.002</td> <td>    0.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FE Growth Net_Inc Mean FQ1 Over 0CY</th>       <td>   -0.0390</td> <td>    0.014</td> <td>   -2.874</td> <td> 0.005</td> <td>   -0.066</td> <td>   -0.012</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>80.232</td> <th>  Durbin-Watson:     </th> <td>   2.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>2990.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.865</td> <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>22.948</td> <th>  Cond. No.          </th> <td>    317.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                             & Price / Book Value & \\textbf{  R-squared:         } &     0.803   \\\\\n",
       "\\textbf{Model:}                                     &        OLS         & \\textbf{  Adj. R-squared:    } &     0.796   \\\\\n",
       "\\textbf{Method:}                                    &   Least Squares    & \\textbf{  F-statistic:       } &     116.7   \\\\\n",
       "\\textbf{Date:}                                      &  Fri, 14 Feb 2025  & \\textbf{  Prob (F-statistic):} &  5.56e-58   \\\\\n",
       "\\textbf{Time:}                                      &      12:51:39      & \\textbf{  Log-Likelihood:    } &   -427.08   \\\\\n",
       "\\textbf{No. Observations:}                          &          179       & \\textbf{  AIC:               } &     868.2   \\\\\n",
       "\\textbf{Df Residuals:}                              &          172       & \\textbf{  BIC:               } &     890.5   \\\\\n",
       "\\textbf{Df Model:}                                  &            6       & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                           &     nonrobust      & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                                    & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}                                      &      -1.5875  &        0.703     &    -2.257  &         0.025        &       -2.976    &       -0.199     \\\\\n",
       "\\textbf{FE Val Roe Mean FQ1 Roll}                   &       1.1325  &        0.044     &    25.598  &         0.000        &        1.045    &        1.220     \\\\\n",
       "\\textbf{Beta 3yr}                                   &       4.1676  &        1.011     &     4.123  &         0.000        &        2.173    &        6.163     \\\\\n",
       "\\textbf{Beta 5yr}                                   &      -3.7333  &        1.065     &    -3.507  &         0.001        &       -5.835    &       -1.632     \\\\\n",
       "\\textbf{FE Growth Net\\_Inc Mean FQ1 Roll Over -2AM} &      -0.0159  &        0.005     &    -3.111  &         0.002        &       -0.026    &       -0.006     \\\\\n",
       "\\textbf{FE Growth Net\\_Inc Mean FQ1 Over -1AM}      &       0.0521  &        0.028     &     1.889  &         0.061        &       -0.002    &        0.107     \\\\\n",
       "\\textbf{FE Growth Net\\_Inc Mean FQ1 Over 0CY}       &      -0.0390  &        0.014     &    -2.874  &         0.005        &       -0.066    &       -0.012     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 80.232 & \\textbf{  Durbin-Watson:     } &    2.052  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.000 & \\textbf{  Jarque-Bera (JB):  } & 2990.190  \\\\\n",
       "\\textbf{Skew:}          & -0.865 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      & 22.948 & \\textbf{  Cond. No.          } &     317.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:     Price / Book Value   R-squared:                       0.803\n",
       "Model:                            OLS   Adj. R-squared:                  0.796\n",
       "Method:                 Least Squares   F-statistic:                     116.7\n",
       "Date:                Fri, 14 Feb 2025   Prob (F-statistic):           5.56e-58\n",
       "Time:                        12:51:39   Log-Likelihood:                -427.08\n",
       "No. Observations:                 179   AIC:                             868.2\n",
       "Df Residuals:                     172   BIC:                             890.5\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=============================================================================================================\n",
       "                                                coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------------------------\n",
       "const                                        -1.5875      0.703     -2.257      0.025      -2.976      -0.199\n",
       "FE Val Roe Mean FQ1 Roll                      1.1325      0.044     25.598      0.000       1.045       1.220\n",
       "Beta 3yr                                      4.1676      1.011      4.123      0.000       2.173       6.163\n",
       "Beta 5yr                                     -3.7333      1.065     -3.507      0.001      -5.835      -1.632\n",
       "FE Growth Net_Inc Mean FQ1 Roll Over -2AM    -0.0159      0.005     -3.111      0.002      -0.026      -0.006\n",
       "FE Growth Net_Inc Mean FQ1 Over -1AM          0.0521      0.028      1.889      0.061      -0.002       0.107\n",
       "FE Growth Net_Inc Mean FQ1 Over 0CY          -0.0390      0.014     -2.874      0.005      -0.066      -0.012\n",
       "==============================================================================\n",
       "Omnibus:                       80.232   Durbin-Watson:                   2.052\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2990.190\n",
       "Skew:                          -0.865   Prob(JB):                         0.00\n",
       "Kurtosis:                      22.948   Cond. No.                         317.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer = StockAnalyzer(\"C:/Users/slick/Downloads/Relative Eval.csv\")\n",
    "#defines what columns to drop if their NaNs are greater than X% of total rows/companies\n",
    "analyzer.CleanData(drop_column_threshold = 0.10)\n",
    "analyzer.classify_features()\n",
    "analyzer.remove_multicollinear_features(threshold = 3.0)\n",
    "analyzer.find_best_model(criterion='adj_r2', p_value = .10)\n",
    "analyzer.get_best_model_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9164ac41-c20b-4ae8-abab-3222d3622680",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlitenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
